{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning_dog_cat_classification_keras.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOy0g4VhEQKH+ixKC2oPVwK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Volviane/Cats_Dogs_classification/blob/master/transfer_learning_dog_cat_classification_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfrp0VYsCmLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Jul 31 20:05:23 2017\n",
        "\n",
        "@author: DIP\n",
        "@Copyright: Dipanjan Sarkar\n",
        "\"\"\"\n",
        "\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.base import clone\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_curve, auc \n",
        "\n",
        "\n",
        "def get_metrics(true_labels, predicted_labels):\n",
        "    \n",
        "    print('Accuracy:', np.round(\n",
        "                        metrics.accuracy_score(true_labels, \n",
        "                                               predicted_labels),\n",
        "                        4))\n",
        "    print('Precision:', np.round(\n",
        "                        metrics.precision_score(true_labels, \n",
        "                                               predicted_labels,\n",
        "                                               average='weighted'),\n",
        "                        4))\n",
        "    print('Recall:', np.round(\n",
        "                        metrics.recall_score(true_labels, \n",
        "                                               predicted_labels,\n",
        "                                               average='weighted'),\n",
        "                        4))\n",
        "    print('F1 Score:', np.round(\n",
        "                        metrics.f1_score(true_labels, \n",
        "                                               predicted_labels,\n",
        "                                               average='weighted'),\n",
        "                        4))\n",
        "                        \n",
        "\n",
        "def train_predict_model(classifier, \n",
        "                        train_features, train_labels, \n",
        "                        test_features, test_labels):\n",
        "    # build model    \n",
        "    classifier.fit(train_features, train_labels)\n",
        "    # predict using model\n",
        "    predictions = classifier.predict(test_features) \n",
        "    return predictions    \n",
        "\n",
        "\n",
        "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n",
        "    \n",
        "    total_classes = len(classes)\n",
        "    level_labels = [total_classes*[0], list(range(total_classes))]\n",
        "\n",
        "    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \n",
        "                                  labels=classes)\n",
        "    cm_frame = pd.DataFrame(data=cm, \n",
        "                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n",
        "                                                  labels=level_labels), \n",
        "                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
        "                                                labels=level_labels)) \n",
        "    print(cm_frame) \n",
        "    \n",
        "def display_classification_report(true_labels, predicted_labels, classes=[1,0]):\n",
        "\n",
        "    report = metrics.classification_report(y_true=true_labels, \n",
        "                                           y_pred=predicted_labels, \n",
        "                                           labels=classes) \n",
        "    print(report)\n",
        "    \n",
        "    \n",
        "    \n",
        "def display_model_performance_metrics(true_labels, predicted_labels, classes=[1,0]):\n",
        "    print('Model Performance metrics:')\n",
        "    print('-'*30)\n",
        "    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n",
        "    print('\\nModel Classification report:')\n",
        "    print('-'*30)\n",
        "    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, \n",
        "                                  classes=classes)\n",
        "    print('\\nPrediction Confusion Matrix:')\n",
        "    print('-'*30)\n",
        "    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n",
        "                             classes=classes)\n",
        "\n",
        "\n",
        "def plot_model_decision_surface(clf, train_features, train_labels,\n",
        "                                plot_step=0.02, cmap=plt.cm.RdYlBu,\n",
        "                                markers=None, alphas=None, colors=None):\n",
        "    \n",
        "    if train_features.shape[1] != 2:\n",
        "        raise ValueError(\"X_train should have exactly 2 columnns!\")\n",
        "    \n",
        "    x_min, x_max = train_features[:, 0].min() - plot_step, train_features[:, 0].max() + plot_step\n",
        "    y_min, y_max = train_features[:, 1].min() - plot_step, train_features[:, 1].max() + plot_step\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
        "                         np.arange(y_min, y_max, plot_step))\n",
        "\n",
        "    clf_est = clone(clf)\n",
        "    clf_est.fit(train_features,train_labels)\n",
        "    if hasattr(clf_est, 'predict_proba'):\n",
        "        Z = clf_est.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
        "    else:\n",
        "        Z = clf_est.predict(np.c_[xx.ravel(), yy.ravel()])    \n",
        "    Z = Z.reshape(xx.shape)\n",
        "    cs = plt.contourf(xx, yy, Z, cmap=cmap)\n",
        "    \n",
        "    le = LabelEncoder()\n",
        "    y_enc = le.fit_transform(train_labels)\n",
        "    n_classes = len(le.classes_)\n",
        "    plot_colors = ''.join(colors) if colors else [None] * n_classes\n",
        "    label_names = le.classes_\n",
        "    markers = markers if markers else [None] * n_classes\n",
        "    alphas = alphas if alphas else [None] * n_classes\n",
        "    for i, color in zip(range(n_classes), plot_colors):\n",
        "        idx = np.where(y_enc == i)\n",
        "        plt.scatter(train_features[idx, 0], train_features[idx, 1], c=color,\n",
        "                    label=label_names[i], cmap=cmap, edgecolors='black', \n",
        "                    marker=markers[i], alpha=alphas[i])\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_model_roc_curve(clf, features, true_labels, label_encoder=None, class_names=None):\n",
        "    \n",
        "    ## Compute ROC curve and ROC area for each class\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    if hasattr(clf, 'classes_'):\n",
        "        class_labels = clf.classes_\n",
        "    elif label_encoder:\n",
        "        class_labels = label_encoder.classes_\n",
        "    elif class_names:\n",
        "        class_labels = class_names\n",
        "    else:\n",
        "        raise ValueError('Unable to derive prediction classes, please specify class_names!')\n",
        "    n_classes = len(class_labels)\n",
        "    y_test = label_binarize(true_labels, classes=class_labels)\n",
        "    if n_classes == 2:\n",
        "        if hasattr(clf, 'predict_proba'):\n",
        "            prob = clf.predict_proba(features)\n",
        "            y_score = prob[:, prob.shape[1]-1] \n",
        "        elif hasattr(clf, 'decision_function'):\n",
        "            prob = clf.decision_function(features)\n",
        "            y_score = prob[:, prob.shape[1]-1]\n",
        "        else:\n",
        "            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n",
        "        \n",
        "        fpr, tpr, _ = roc_curve(y_test, y_score)      \n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label='ROC curve (area = {0:0.2f})'\n",
        "                                 ''.format(roc_auc),\n",
        "                 linewidth=2.5)\n",
        "        \n",
        "    elif n_classes > 2:\n",
        "        if hasattr(clf, 'predict_proba'):\n",
        "            y_score = clf.predict_proba(features)\n",
        "        elif hasattr(clf, 'decision_function'):\n",
        "            y_score = clf.decision_function(features)\n",
        "        else:\n",
        "            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n",
        "\n",
        "        for i in range(n_classes):\n",
        "            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "        ## Compute micro-average ROC curve and ROC area\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "        ## Compute macro-average ROC curve and ROC area\n",
        "        # First aggregate all false positive rates\n",
        "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "        # Then interpolate all ROC curves at this points\n",
        "        mean_tpr = np.zeros_like(all_fpr)\n",
        "        for i in range(n_classes):\n",
        "            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "        # Finally average it and compute AUC\n",
        "        mean_tpr /= n_classes\n",
        "        fpr[\"macro\"] = all_fpr\n",
        "        tpr[\"macro\"] = mean_tpr\n",
        "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "        ## Plot ROC curves\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "                 label='micro-average ROC curve (area = {0:0.2f})'\n",
        "                       ''.format(roc_auc[\"micro\"]), linewidth=3)\n",
        "\n",
        "        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "                 label='macro-average ROC curve (area = {0:0.2f})'\n",
        "                       ''.format(roc_auc[\"macro\"]), linewidth=3)\n",
        "\n",
        "        for i, label in enumerate(class_labels):\n",
        "            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "                                           ''.format(label, roc_auc[i]), \n",
        "                     linewidth=2, linestyle=':')\n",
        "    else:\n",
        "        raise ValueError('Number of classes should be atleast 2 or more')\n",
        "        \n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx8yRx6Ve88l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load helper file\n",
        "link = \"https://drive.google.com/file/d/1Cn0B9Zr2irUnZcHqODT9IilGHf9fZ61R/view?usp=sharing\"\n",
        "\n",
        "_, id_t = link.split('d/')\n",
        "\n",
        "id = id_t.split('/')[0]\n",
        "\n",
        "print (\"Loading file ...\")\n",
        "\n",
        "print (id) # Verify that you have everything after '='\n",
        "\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "file_id = id\n",
        "downloaded = drive.CreateFile({'id':file_id})\n",
        "downloaded.FetchMetadata(fetch_all=True)\n",
        "downloaded.GetContentFile(downloaded.metadata['title'])\n",
        "print (\"Completed\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmKCWRF5fSiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip Cat_Dog_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45Wan8N_f1zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls Cat_Dog_data/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lp6W6UddfLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "%matplotlib inline\n",
        "\n",
        "# encode text category labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "\n",
        "from keras.applications import vgg16\n",
        "from keras.models import Model\n",
        "import keras\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G8Z36Yyf1Qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = glob.glob('Cat_Dog_data/train/cat/*')\n",
        "files1 = glob.glob('Cat_Dog_data/train/dog/*')\n",
        "\n",
        "cat_files = [fn for fn in files if 'cat' in fn]\n",
        "dog_files = [fn for fn in files1 if 'dog' in fn]\n",
        "len(cat_files), len(dog_files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cSbWealeEBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_train = np.random.choice(cat_files, size=1500, replace=False)\n",
        "dog_train = np.random.choice(dog_files, size=1500, replace=False)\n",
        "cat_files = list(set(cat_files) - set(cat_train))\n",
        "dog_files = list(set(dog_files) - set(dog_train))\n",
        "\n",
        "cat_val = np.random.choice(cat_files, size=500, replace=False)\n",
        "dog_val = np.random.choice(dog_files, size=500, replace=False)\n",
        "cat_files = list(set(cat_files) - set(cat_val))\n",
        "dog_files = list(set(dog_files) - set(dog_val))\n",
        "\n",
        "cat_test = np.random.choice(cat_files, size=500, replace=False)\n",
        "dog_test = np.random.choice(dog_files, size=500, replace=False)\n",
        "\n",
        "print('Cat datasets:', cat_train.shape, cat_val.shape, cat_test.shape)\n",
        "print('Dog datasets:', dog_train.shape, dog_val.shape, dog_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HU_YFephagT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = 'training_data'\n",
        "val_dir = 'validation_data'\n",
        "test_dir = 'test_data'\n",
        "\n",
        "train_files = np.concatenate([cat_train, dog_train])\n",
        "validate_files = np.concatenate([cat_val, dog_val])\n",
        "test_files = np.concatenate([cat_test, dog_test])\n",
        "\n",
        "os.mkdir(train_dir) if not os.path.isdir(train_dir) else None\n",
        "os.mkdir(val_dir) if not os.path.isdir(val_dir) else None\n",
        "os.mkdir(test_dir) if not os.path.isdir(test_dir) else None\n",
        "\n",
        "for fn in train_files:\n",
        "    shutil.copy(fn, train_dir)\n",
        "\n",
        "for fn in validate_files:\n",
        "    shutil.copy(fn, val_dir)\n",
        "    \n",
        "for fn in test_files:\n",
        "    shutil.copy(fn, test_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGR17cgwhuPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!ls training_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4hFqRpEiaUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_DIM = (150, 150)\n",
        "\n",
        "train_files = glob.glob('training_data/*')\n",
        "train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]\n",
        "train_imgs = np.array(train_imgs)\n",
        "#print(train_imgs.shape)\n",
        "train_labels = [fn.split('/')[1].split('.')[0].strip() for fn in train_files] #.split('\\\\')[1]\n",
        "print(\"Train label : \",train_labels)\n",
        "validation_files = glob.glob('validation_data/*')\n",
        "validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in validation_files]\n",
        "validation_imgs = np.array(validation_imgs)\n",
        "validation_labels = [fn.split('/')[1].split('.')[0].strip() for fn in validation_files]\n",
        "print(\"validation label : \",validation_labels)\n",
        "\n",
        "print('Train dataset shape:', train_imgs.shape, \n",
        "      '\\tValidation dataset shape:', validation_imgs.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0F7K_ZUjOUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_imgs_scaled = train_imgs.astype('float32')\n",
        "validation_imgs_scaled  = validation_imgs.astype('float32')\n",
        "train_imgs_scaled /= 255\n",
        "validation_imgs_scaled /= 255\n",
        "\n",
        "print(train_imgs[0].shape)\n",
        "array_to_img(train_imgs[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJWlE-wKmV-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 30\n",
        "num_classes = 2\n",
        "epochs = 30\n",
        "input_shape = (150, 150, 3)\n",
        "\n",
        "# encode text category labels\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(train_labels)\n",
        "train_labels_enc = le.transform(train_labels)\n",
        "validation_labels_enc = le.transform(validation_labels)\n",
        "\n",
        "print(train_labels[1495:1505], train_labels_enc[1495:1505])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50rR2KxLmnde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkT3Gik1nL66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', \n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAIC4djTnWX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x=train_imgs_scaled, y=train_labels_enc,\n",
        "                    validation_data=(validation_imgs_scaled, validation_labels_enc),\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFVgn_cqo7Iy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('Basic CNN Performance', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "epoch_list = list(range(1,31))\n",
        "ax1.plot(epoch_list, history.history['acc'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, history.history['val_acc'], label='Validation Accuracy')\n",
        "ax1.set_xticks(np.arange(0, 31, 5))\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
        "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(np.arange(0, 31, 5))\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD8P2Q3Spox3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmL3-Am1qasg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', \n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "              \n",
        "history = model.fit(x=train_imgs_scaled, y=train_labels_enc,\n",
        "                    validation_data=(validation_imgs_scaled, validation_labels_enc),\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16-sByveqbjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('Basic CNN Performance', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "epoch_list = list(range(1,31))\n",
        "ax1.plot(epoch_list, history.history['acc'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, history.history['val_acc'], label='Validation Accuracy')\n",
        "ax1.set_xticks(np.arange(0, 31, 5))\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
        "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(np.arange(0, 31, 5))\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBnB31ZzrJeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNDZmKpCrsy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"cats_dogs_basic_cnn.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6ds9OcertZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,\n",
        "                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n",
        "                                   horizontal_flip=True, fill_mode='nearest')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESBlkT5ysToU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_id = 2595\n",
        "cat_generator = train_datagen.flow(train_imgs[img_id:img_id+1], train_labels[img_id:img_id+1],\n",
        "                                   batch_size=1)\n",
        "cat = [next(cat_generator) for i in range(0,5)]\n",
        "fig, ax = plt.subplots(1,5, figsize=(16, 6))\n",
        "print('Labels:', [item[1][0] for item in cat])\n",
        "l = [ax[i].imshow(cat[i][0][0]) for i in range(0,5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuEjb4Z9847D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_id = 1990\n",
        "dog_generator = train_datagen.flow(train_imgs[img_id:img_id+1], train_labels[img_id:img_id+1],\n",
        "                                   batch_size=1)\n",
        "dog = [next(dog_generator) for i in range(0,5)]\n",
        "fig, ax = plt.subplots(1,5, figsize=(15, 6))\n",
        "print('Labels:', [item[1][0] for item in dog])\n",
        "l = [ax[i].imshow(dog[i][0][0]) for i in range(0,5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JuTQ3z69RvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = train_datagen.flow(train_imgs, train_labels_enc, batch_size=30)\n",
        "val_generator = val_datagen.flow(validation_imgs, validation_labels_enc, batch_size=20)\n",
        "input_shape = (150, 150, 3)\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', \n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100,\n",
        "                              validation_data=val_generator, validation_steps=50, \n",
        "                              verbose=1)              \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUAjJGCh9wzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('Basic CNN Performance', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "epoch_list = list(range(1,101))\n",
        "print(len(epoch_list), len(history.history['acc']))\n",
        "ax1.plot(epoch_list, history.history['acc'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, history.history['val_acc'], label='Validation Accuracy')\n",
        "ax1.set_xticks(np.arange(0, 31, 5))\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
        "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(np.arange(0, 31, 5))\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdCuDznGE6El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"cats_dogs_cnn_img_aug.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4bgwRLaIjrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReEWzo5dF6R9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "vgg = vgg16.VGG16(include_top=False, weights='imagenet', \n",
        "                                     input_shape=input_shape)\n",
        "\n",
        "output = vgg.layers[-1].output\n",
        "output = keras.layers.Flatten()(output)\n",
        "vgg_model = Model(vgg.input, output)\n",
        "\n",
        "vgg_model.trainable = False\n",
        "for layer in vgg_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "import pandas as pd\n",
        "pd.set_option('max_colwidth', -1)\n",
        "layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\n",
        "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAxA_z3wIdCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bottleneck_feature_example = vgg.predict(train_imgs_scaled[0:1])\n",
        "print(bottleneck_feature_example.shape)\n",
        "plt.imshow(bottleneck_feature_example[0][:,:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2BXMn2rJm--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_bottleneck_features(model, input_imgs):\n",
        "    features = model.predict(input_imgs, verbose=0)\n",
        "    return features\n",
        "    \n",
        "train_features_vgg = get_bottleneck_features(vgg_model, train_imgs_scaled)\n",
        "validation_features_vgg = get_bottleneck_features(vgg_model, validation_imgs_scaled)\n",
        "\n",
        "print('Train Bottleneck Features:', train_features_vgg.shape, \n",
        "      '\\tValidation Bottleneck Features:', validation_features_vgg.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X596LzuDKM-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "\n",
        "input_shape = vgg_model.output_shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(input_shape,)))\n",
        "model.add(Dense(512, activation='relu', input_dim=input_shape))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnKHHr0iKnov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x=train_features_vgg, y=train_labels_enc,\n",
        "                    validation_data=(validation_features_vgg, validation_labels_enc),\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUo9v-0tK_qR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('Basic CNN Performance', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "epoch_list = list(range(1,31))\n",
        "ax1.plot(epoch_list, history.history['acc'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, history.history['val_acc'], label='Validation Accuracy')\n",
        "ax1.set_xticks(np.arange(0, 31, 5))\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
        "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(np.arange(0, 31, 5))\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhdTncOULmxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('cats_dogs_tlearn_basic_cnn.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohHgvm8PL1qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,\n",
        "                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n",
        "                                   horizontal_flip=True, fill_mode='nearest')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow(train_imgs, train_labels_enc, batch_size=30)\n",
        "val_generator = val_datagen.flow(validation_imgs, validation_labels_enc, batch_size=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeWaUi7WMAkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(vgg_model)\n",
        "model.add(Dense(512, activation='relu', input_dim=input_shape))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100,\n",
        "                              validation_data=val_generator, validation_steps=50, \n",
        "                              verbose=1)              "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBaR49ktMOgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('Basic CNN Performance', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "epoch_list = list(range(1,101))\n",
        "ax1.plot(epoch_list, history.history['acc'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, history.history['val_acc'], label='Validation Accuracy')\n",
        "ax1.set_xticks(np.arange(0, 31, 5))\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
        "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(np.arange(0, 31, 5))\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HySJcXFSWoUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"cats_dogs_tlearn_img_aug_cnn.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWi9YurDWz9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg_model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in vgg_model.layers:\n",
        "    if layer.name in ['block5_conv1', 'block4_conv1']:\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "        \n",
        "layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\n",
        "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVCG2mBzW7sQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,\n",
        "                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n",
        "                                   horizontal_flip=True, fill_mode='nearest')\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow(train_imgs, train_labels_enc, batch_size=30)\n",
        "val_generator = val_datagen.flow(validation_imgs, validation_labels_enc, batch_size=20)\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(vgg_model)\n",
        "model.add(Dense(512, activation='relu', input_dim=input_shape))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100,\n",
        "                              validation_data=val_generator, validation_steps=50, \n",
        "                              verbose=1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bNtq1gJXAif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('cats_dogs_tlearn_finetune_img_aug_cnn.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vpIeKzyjXFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load dependencies\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
        "from keras.models import load_model\n",
        "#import model_evaluation_utils as meu\n",
        "%matplotlib inline\n",
        "\n",
        "# load saved models\n",
        "basic_cnn = load_model('cats_dogs_basic_cnn.h5')\n",
        "img_aug_cnn = load_model('cats_dogs_cnn_img_aug.h5')\n",
        "tl_cnn = load_model('cats_dogs_tlearn_basic_cnn.h5')\n",
        "tl_img_aug_cnn = load_model('cats_dogs_tlearn_img_aug_cnn.h5')\n",
        "tl_img_aug_finetune_cnn = load_model('cats_dogs_tlearn_finetune_img_aug_cnn.h5')\n",
        "\n",
        "# load other configurations\n",
        "IMG_DIM = (150, 150)\n",
        "input_shape = (150, 150, 3)\n",
        "num2class_label_transformer = lambda l: ['cat' if x == 0 else 'dog' for x in l]\n",
        "class2num_label_transformer = lambda l: [0 if x == 'cat' else 1 for x in l]\n",
        "\n",
        "# load VGG model for bottleneck features\n",
        "from keras.applications import vgg16\n",
        "from keras.models import Model\n",
        "import keras\n",
        "\n",
        "vgg = vgg16.VGG16(include_top=False, weights='imagenet', \n",
        "                  input_shape=input_shape)\n",
        "output = vgg.layers[-1].output\n",
        "output = keras.layers.Flatten()(output)\n",
        "vgg_model = Model(vgg.input, output)\n",
        "vgg_model.trainable = False\n",
        "\n",
        "def get_bottleneck_features(model, input_imgs):\n",
        "    features = model.predict(input_imgs, verbose=0)\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beI8fheCjbbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_DIM = (150, 150)\n",
        "\n",
        "test_files = glob.glob('test_data/*')\n",
        "test_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in test_files]\n",
        "test_imgs = np.array(test_imgs)\n",
        "test_labels = [fn.split('/')[1].split('.')[0].strip() for fn in test_files]\n",
        "\n",
        "test_imgs_scaled = test_imgs.astype('float32')\n",
        "test_imgs_scaled /= 255\n",
        "test_labels_enc = class2num_label_transformer(test_labels)\n",
        "\n",
        "print('Test dataset shape:', test_imgs.shape)\n",
        "print(test_labels[0:5], test_labels_enc[0:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzQDbLsok-GH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = basic_cnn.predict_classes(test_imgs_scaled, verbose=0)\n",
        "predictions = num2class_label_transformer(predictions)\n",
        "display_model_performance_metrics(true_labels=test_labels, predicted_labels=predictions, \n",
        "                                      classes=list(set(test_labels)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGBdgi6GlErg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = img_aug_cnn.predict_classes(test_imgs_scaled, verbose=0)\n",
        "predictions = num2class_label_transformer(predictions)\n",
        "display_model_performance_metrics(true_labels=test_labels, predicted_labels=predictions, \n",
        "                                      classes=list(set(test_labels)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luVMbl5rbNxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_bottleneck_features = get_bottleneck_features(vgg_model, test_imgs_scaled)\n",
        "\n",
        "predictions = tl_cnn.predict_classes(test_bottleneck_features, verbose=0)\n",
        "predictions = num2class_label_transformer(predictions)\n",
        "display_model_performance_metrics(true_labels=test_labels, predicted_labels=predictions, \n",
        "                                      classes=list(set(test_labels)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKlMs_9VbS96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = tl_img_aug_cnn.predict_classes(test_imgs_scaled, verbose=0)\n",
        "predictions = num2class_label_transformer(predictions)\n",
        "display_model_performance_metrics(true_labels=test_labels, predicted_labels=predictions, \n",
        "                                      classes=list(set(test_labels)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae8ZXJvBbZEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = tl_img_aug_finetune_cnn.predict_classes(test_imgs_scaled, verbose=0)\n",
        "predictions = num2class_label_transformer(predictions)\n",
        "display_model_performance_metrics(true_labels=test_labels, predicted_labels=predictions, \n",
        "                                      classes=list(set(test_labels)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krC1TJBabjgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# worst model - basic CNN \n",
        "plot_model_roc_curve(basic_cnn, test_imgs_scaled, \n",
        "                         true_labels=test_labels_enc, \n",
        "                         class_names=[0, 1]) \n",
        "\n",
        "# best model - transfer learning with fine-tuning & image augmentation \n",
        "plot_model_roc_curve(tl_img_aug_finetune_cnn, test_imgs_scaled, \n",
        "                         true_labels=test_labels_enc, \n",
        "                         class_names=[0, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kms4uYNAbsGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}